{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zalando Bot: AI-Powered Fashion Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Google Gemma2 2B & 9B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma2 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_id = \"google/gemma-2-2b-it\"\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# cuda | cpu | auto\n",
    "device = \"cuda\"\n",
    "\n",
    "# If the model is too large for the GPU, you can offload some parts of the model to the CPU or disk, which can help save GPU memory. \n",
    "# Use the device_map=\"auto\" option, and PyTorch will automatically split the model across available devices.\n",
    "# Alternatively, you can specify \"cpu\" for the parts of the model that can run on the CPU:\n",
    "# device={\"transformer\": \"cuda\", \"lm_head\": \"cpu\"}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, low_cpu_mem_usage=True, device_map=device, torch_dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = [{\"role\": \"user\", \"content\": \"Write a hello world program\"}]\n",
    "prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma2 9B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_id = \"google/gemma-2-9b-it\"\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# cuda | cpu | auto\n",
    "device = \"auto\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, low_cpu_mem_usage=True, device_map=device, torch_dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = [{\"role\": \"user\", \"content\": \"Write a hello world program\"}]\n",
    "prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama Gemma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama Gemma2 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  I'd love to help!  To give you the best recommendations, tell me more about what you're looking for:\n",
      "\n",
      "**1. What kind of occasion are you dressing for?** \n",
      "   * Casual outings with friends?\n",
      "   * A fancy dinner party?\n",
      "   * Wedding guest attire?\n",
      "   * Going to a festival? \n",
      "\n",
      "**2. What style are you interested in?**\n",
      "   * Flowy maxi dress? \n",
      "   * Short and sassy sundress? \n",
      "   * Something vintage-inspired? \n",
      "   * Bodycon silhouette?  \n",
      "   * Bohemian-style with lace or embroidery?  \n",
      "\n",
      "**3. What's your budget range for the dress?** \n",
      "   * Under $50? \n",
      "   * $50-$100? \n",
      "   * $100+ ?\n",
      "\n",
      "**4. Do you have any specific fabric preferences, like cotton, silk, or something else?**\n",
      "   * Do you prefer something breathable and light for warm weather, or do you want something with a bit more warmth and coverage?\n",
      "\n",
      "\n",
      "Once I know a little more about your style and needs, I can give you some tailored recommendations. ðŸ˜Š \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def talk_to_bot(user_input):\n",
    "    response = ollama.chat(\n",
    "        model=\"gemma2:2b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": user_input}]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "# Example usage\n",
    "user_query = \"Hello, can you help me find a summer dress?\"\n",
    "bot_response = talk_to_bot(user_query)\n",
    "print(\"Bot: \", bot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama Gemma2 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  I can definitely help you find a summer dress! To give you the best recommendations, I need some more information about what you're looking for. \n",
      "\n",
      "Tell me about:\n",
      "\n",
      "* **Your style:** What kind of aesthetic do you like? (e.g., bohemian, classic, modern, trendy)\n",
      "* **The occasion:** Are you looking for a dress for a special event, casual outings, or something in between?\n",
      "* **Your budget:** How much are you willing to spend?\n",
      "* **Your preferences:** \n",
      "\n",
      "Do you have any preferences for:\n",
      "\n",
      "* **Length:** (e.g., maxi, midi, mini)\n",
      "* **Color/pattern:** \n",
      "* **Fabric:** (e.g., cotton, linen, silk)\n",
      "* **Sleeves:** (e.g., sleeveless, short sleeves, long sleeves)\n",
      "* **Features:** (e.g., pockets, ruffles, lace)\n",
      "\n",
      "The more details you give me, the better I can help you find the perfect summer dress!\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def talk_to_bot(user_input):\n",
    "    response = ollama.chat(\n",
    "        model=\"gemma2:latest\",\n",
    "        messages=[{\"role\": \"user\", \"content\": user_input}]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "# Example usage\n",
    "user_query = \"Hello, can you help me find a summer dress?\"\n",
    "bot_response = talk_to_bot(user_query)\n",
    "print(\"Bot: \", bot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = 'gemma2:2b'\n",
    "\n",
    "llm = ChatOllama(model=ollama_model, keep_alive=\"3h\", max_tokens=512, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt template\n",
    "template = \"\"\"<bos><start_of_turn>user\\nAnswer the question based only on the following context and extract out a meaningful answer. \\\n",
    "Please write in full sentences with correct spelling and punctuation. if it makes sense use lists. \\\n",
    "If the context doen't contain the answer, just respond that you are unable to find an answer. \\\n",
    "\n",
    "CONTEXT: Zalando is a European online fashion and lifestyle platform founded in 2008 in Berlin, Germany. It offers a wide range of products including clothing, footwear, accessories, and beauty items for men, women, and children. Zalando operates in multiple countries across Europe, serving millions of customers.\\nThe platform partners with a variety of global fashion brands, from high-end luxury labels to more affordable options, and also provides its own private label products. Zalando is known for its extensive catalog, user-friendly shopping experience, and services like free delivery and returns. It also offers personalized recommendations, making it a popular destination for fashion-conscious shoppers.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "<end_of_turn>\n",
    "<start_of_turn>model\\n\n",
    "ANSWER:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the RAG chain using LCEL with prompt printing and streaming output\n",
    "chain = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zalando is an online fashion and lifestyle platform founded in Berlin, Germany, that offers a wide variety of products including clothing, footwear, accessories, and beauty items for men, women, and children. \n",
      "\n",
      "\n",
      "Here are some key points about Zalando:\n",
      "\n",
      "* **Offers:** Clothing, footwear, accessories, and beauty items\n",
      "* **Target Audience:** Men, women, and children\n",
      "* **Global Reach:** Operates in multiple countries across Europe\n",
      "* **Partnerships:** Works with both high-end luxury brands and more affordable options. \n",
      "* **Private Label:** Offers its own private label products.\n",
      "* **Features:**  Extensive catalog, user-friendly shopping experience, free delivery and returns, personalized recommendations. \n"
     ]
    }
   ],
   "source": [
    "question = \"What is Zalando ?\"\n",
    "for chunk in chain.stream(question):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
